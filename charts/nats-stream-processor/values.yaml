# Default values for nats-stream-processor.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Note: replicaCount is ignored when autoscaling.enabled=true
replicaCount: 3

image:
  repository: ghcr.io/richardr1126/nats-stream-processor
  pullPolicy: IfNotPresent
  tag: ""

imagePullSecrets: []

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  automount: true
  annotations: {}
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext:
  fsGroup: 1000

securityContext:
  allowPrivilegeEscalation: false
  runAsNonRoot: true
  runAsUser: 1000
  readOnlyRootFilesystem: true
  capabilities:
    drop:
    - ALL

service:
  type: ClusterIP
  port: 8080
  targetPort: 8080

resources:
  requests:
    memory: "1000Mi"
    cpu: "3500m"
  limits:
    memory: "3000Mi"
    cpu: "3800m"

livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: http
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

envFrom:
  - secretRef:
      name: nats-stream-processor-env

# Volume configuration for model cache (required for read-only filesystem)
volumes:
  modelCache:
    enabled: true
    # Use emptyDir for ephemeral cache (models downloaded on each pod start)
    # For persistent cache across restarts, use persistentVolumeClaim
    type: emptyDir  # or "persistentVolumeClaim"
    size: "2Gi"
    mountPath: "/var/cache/models"
    # Only used if type is persistentVolumeClaim
    storageClass: ""  # Use default storage class
    accessMode: "ReadWriteOnce"
  # Temporary directory volume (required for PyTorch/dill with read-only filesystem)
  tmp:
    enabled: true
    size: "1Gi"
    mountPath: "/tmp"
  # Home directory volume (required for user-level cache with read-only filesystem)
  home:
    enabled: true
    size: "512Mi"
    mountPath: "/home/appuser"

nodeSelector:
  cloud.google.com/gke-nodepool: "ml-pool"

tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "ml"
    effect: "NoSchedule"

# Horizontal Pod Autoscaler configuration
autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 6  # Matches ML_MAX_NODES from gke-cluster.py
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  # Scale up quickly to handle burst traffic
  scaleUpStabilizationWindowSeconds: 0
  scaleUpPercentage: 100  # Double replicas
  scaleUpPods: 2          # Or add 2 pods
  scaleUpPeriodSeconds: 30
  # Scale down slowly to avoid thrashing
  scaleDownStabilizationWindowSeconds: 300  # 5 minutes
  scaleDownPercentage: 50  # Remove half
  scaleDownPods: 1         # Or remove 1 pod
  scaleDownPeriodSeconds: 60
